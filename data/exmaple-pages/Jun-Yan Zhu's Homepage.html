
<!-- saved from url=(0042)https://people.eecs.berkeley.edu/~junyanz/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=GBK">
<title>Jun-Yan Zhu's Homepage</title>
<link rel="shortcut icon" href="http://cg.cs.tsinghua.edu.cn/people/~xianying/favicon.ico">
<style type="text/css">
body {
	margin-top: 30px;
	margin-bottom: 30px;
	margin-left: 100px;
	margin-right: 100px;
}
p {
	margin-top: 0px;
	margin-bottom: 0px;
}

.caption {
	font-size: 34px;
	font-weight: normal;
	color: #000;
	font-family: Constantia, "Lucida Bright", "DejaVu Serif", Georgia, serif;
}
.caption-1 {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
}
.caption-2 {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	font-weight: bold;
	color: #990000;
}
.caption-3 {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	font-weight: bold;
	color: #F00;
}

.caption-4 {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	color: #990000;
}
.content {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	text-align: justify;
}
.content a {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	color: #000;
}
.content strong a {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	color: #990000;
}
.title-small {
	font-size: 20px;
	font-family: Georgia, "Times New Roman", Times, serif;
	font-weight: bold;
	color: #F90;
}
.title-large {
	font-size: 28px;
	font-family: Georgia, "Times New Roman", Times, serif;
	font-weight: bold;
	color: #000;
}
.margin {
	font-size: 10px;
	line-height: 10px;
}
.margin-small {
	font-size: 5px;
	line-height: 5px;
}
.margin-large {
	font-size: 16px;
	line-height: 16px;
}
a:link {
	text-decoration: none;
}
a:visited {
	text-decoration: none;
}
content a:link {
	text-decoration: none;
}
content a:visited {
	text-decoration: none;
}
a:hover {
	text-decoration: underline;
}
a:active {
	text-decoration: underline;
	color: #06F;
	font-family: Tahoma, Geneva, sans-serif;
}
strong a:active {
	text-decoration: underline;
	color: #06F;
}
</style>
<script async="" src="./Jun-Yan Zhu&#39;s Homepage_files/analytics.js.download"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-53682931-1', 'auto');
  ga('send', 'pageview');

</script></head>



<body>

<table border="0" width="100%">
  <tbody>

    <tr>
    <td width="185"><img src="./Jun-Yan Zhu&#39;s Homepage_files/portrait.jpg" border="1" height="270"></td>
    <td width="15"></td>
    <td></td>
    <td><table border="0" width="100%">
      <tbody><tr height="10">
        <td colspan="2"></td></tr>


         <tr height="20">
        <td>
           <p class="caption">Jun-Yan Zhu</p>
           <p class="content">Ph.D. candidate</p>
            <p class="content">Berkeley AI Research (BAIR) Lab</p>
           <p class="content">Department of EECS
            </p><p class="content">University of California, Berkeley</p>
        </td>
      </tr>

      <tr height="40">
        <td><table border="0" width="100%">
          <tbody><tr height="20">
            <td width="55">

              <p class="content"><strong>Email: </strong></p></td>
            <td>
              <p class="content"> junyanz at eecs dot berkeley dot edu</p></td>
          </tr>
          <tr height="20">
            <td width="55">
              <p class="content"><strong>Office: </strong></p></td>
            <td>
              <p class="content">Sutardja Dai Hall 7th floor <br>
             University of California, Berkeley<br>
             Berkeley, CA 94704<br></p></td>
          </tr>
        </tbody></table></td>
      </tr>

      <tr height="20">
        <td>
          <p class="margin">&nbsp;</p>
          <p class="content"><strong><a href="https://people.eecs.berkeley.edu/~junyanz/pdf/junyanz_cv.pdf">CV</a></strong> | <strong><a href="https://github.com/junyanz/">GitHub</a></strong> | <strong><a href="http://scholar.google.com/citations?user=UdpacsMAAAAJ&amp;hl=en">Google Scholar</a></strong> | <strong><a href="https://arxiv.org/a/zhu_j_5.html">Arxiv</a></strong></p>
        </td>
      </tr>
      <tr height="20">
        <td colspan="2"></td></tr>
    </tbody></table></td>
  </tr>
</tbody></table>
<p class="margin">&nbsp;</p>

<table border="0">
  <tbody>
    <tr>
      <td width="900"> <p align="justify" class="content">I am a Ph.D. student at the Berkeley AI Research Lab, working on computer vision, graphics and machine learning with Professor <strong><a href="http://www.eecs.berkeley.edu/~efros/" target="_blank" rel="nofollow" class="caption-2">Alexei A. Efros</a></strong>. I was a Ph.D. student at CMU from 2012-13. My research goal is to build machines capable of recreating our visual world. I am currently supported by a <strong><a href="https://research.fb.com/fellows/zhu-jun-yan/" target="_blank" rel="nofollow" class="caption-2">Facebook Fellowship</a> </strong>.</p>
        <br>

    <p align="justify" class="content">I received my B.E in Computer Science from Tsinghua University in 2012, where I worked with Professor <strong><a href="http://pages.ucsd.edu/~ztu/" target="_blank" rel="nofollow" class="caption-2">Zhuowen Tu</a></strong> and Dr. <strong><a href="http://research.microsoft.com/en-us/people/echang/" target="_blank" rel="nofollow" class="caption-2">Eric Chang</a></strong> at Microsoft Research Asia. I was also a member of Tsinghua's Graphics Group led by Professor <strong><a href="http://cg.cs.tsinghua.edu.cn/" target="_blank" rel="nofollow" class="caption-2">Shi-Min Hu</a> </strong>.</p>
    </td></tr>
  </tbody>
</table>

<br>

<p class="title-large">Cat Papers</p>
<p class="content">If you like cats, and love reading cool vision, learning and graphics papers, check out  <strong><a href="https://github.com/junyanz/CatPapers">GitHub</a></strong> | <strong><a href="https://people.eecs.berkeley.edu/~junyanz/cat/cat_papers.html">Webpage</a></strong>.
<br>
<br>

</p><p class="title-large">Workshops</p>
<p class="content">ICML 2017 <strong><a href="http://icmlviz.github.io/">Workshop</a></strong>  on Visualization for Deep Learning.</p>
<p class="content">SIGGRAPH Asia 2014 invited <strong><a href="http://kevinkaixu.net/courses/ddvc.html">Course</a></strong> on Data-Driven Visual Computing.</p>
<br>


<p id="sect-publications" class="title-large">Publications</p>


<table border="0">
  <tbody><tr>
    <td width="140"><a href="https://junyanz.github.io/CycleGAN/"><img src="./Jun-Yan Zhu&#39;s Homepage_files/CycleGAN.jpg" border="1" width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><strong>Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</strong></p>
      <p class="content">Jun-Yan Zhu*, <a href="https://taesung.me/">Taesung Park</a>*, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, and <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a></p>
      <p class="content">In IEEE International Conference on Computer Vision (<strong>ICCV</strong>), 2017</p><p>
				</p><p class="content">(*indicates equal contributions)</p>

	 <p class="margin-small">&nbsp;</p>
	   <p class="content">
      <strong><a href="https://junyanz.github.io/CycleGAN/">Project</a></strong> | <strong><a href="https://github.com/junyanz/CycleGAN">Torch</a></strong> | <strong><a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">PyTorch</a></strong> | <strong><a href="https://arxiv.org/pdf/1703.10593.pdf">Paper</a></strong> | <strong><a href="https://people.eecs.berkeley.edu/~junyanz/talks/pix2pix_cyclegan.pptx">Slides</a></strong> |
			<strong><a href="https://junyanz.github.io/CycleGAN/CycleGAN.txt">BibTex</a></strong></p>
      </td></tr>
</tbody></table>



<table border="0">
  <tbody><tr>
    <td width="140"><a href="https://phillipi.github.io/pix2pix/"><img src="./Jun-Yan Zhu&#39;s Homepage_files/pix2pix.jpg" border="1" width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><strong>Image-to-Image Translation with Conditional Adversarial Nets</strong></p>
      <p class="content"><a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, Jun-Yan Zhu, <a href="https://people.eecs.berkeley.edu/~tinghuiz/">Tinghui Zhou</a>, and <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a></p>
      <p class="content">In IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2017</p>
			<p class="content">See neat uses of <strong> <a href="https://twitter.com/search?vertical=default&amp;q=pix2pix&amp;src=typd">#pix2pix</a> </strong> on Twitter.
			 </p><p class="margin-small">&nbsp;</p>
	   <p class="content">
      <strong><a href="https://phillipi.github.io/pix2pix/">Project</a></strong> |
			<strong><a href="https://github.com/phillipi/pix2pix">Torch</a></strong> |
			<strong><a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">PyTorch</a></strong> |
			<strong><a href="https://arxiv.org/pdf/1611.07004v1.pdf">Paper</a></strong> |
		  <strong><a href="https://people.eecs.berkeley.edu/~junyanz/talks/pix2pix_cyclegan.pptx">Slides</a></strong> |
      <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/pix2pix/pix2pix.bib">BibTex</a></strong></p>
      </td></tr>
</tbody></table>

<p class="margin">&nbsp;</p>
<table border="0">
  <tbody><tr>
    <td width="140"><a href="./Jun-Yan Zhu&#39;s Homepage_files/icolor_demo.gif"><img src="./Jun-Yan Zhu&#39;s Homepage_files/icolor_demo.gif" border="1" width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><strong>Real-Time User-Guided Image Colorization with Learned Deep Priors</strong></p>
      <p class="content"><a href="http://richzhang.github.io/">Richard Zhang</a>*, Jun-Yan Zhu*,  <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, <a href="http://young-geng.xyz/">Xinyang Geng</a>, Angela S. Lin, Tianhe Yu, and <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a></p>
      <p class="content">In ACM Transactions on Graphics (<strong>SIGGRAPH</strong>), 2017</p>
			<p class="content"> (*indicates equal contributions)</p>
			<p class="content">
			<strong> <a href="https://richzhang.github.io/ideepcolor/">Project</a></strong> |
			<strong> <a href="https://github.com/junyanz/interactive-deep-colorization">GitHub</a></strong> |
			<strong> <a href="https://www.youtube.com/watch?v=eL5ilZgM89Q&amp;feature=youtu.be">Youtube</a></strong> |
			<strong> <a href="https://arxiv.org/abs/1705.02999">Paper</a></strong> |
		  <strong> <a href="https://www.youtube.com/watch?v=FTzcFsz2xqw&amp;feature=youtu.be&amp;t=992">Talk</a><a></a></strong><a> |
      <strong> </strong></a><strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/ideepcolor/ideepcolor.txt">BibTex</a> </strong></p>
      </td></tr>
</tbody></table>

<table border="0">
  <tbody><tr>
    <td width="140"><a href="https://people.eecs.berkeley.edu/~junyanz/"><img src="./Jun-Yan Zhu&#39;s Homepage_files/lfv.jpg" border="1" width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><strong>Light Field Video Capture Using a Learning-Based Hybrid Imaging System</strong></p>
			<p class="content"><a href="https://people.eecs.berkeley.edu/~tcwang0509/">Ting-Chun Wang</a>, Jun-Yan Zhu, <a href="http://nkhademi.com/">Nima Khademi Kalantari</a>, <a href="http://www.eecs.berkeley.edu/~efros/"> Alexei A. Efros</a>, and <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a></p>
        <p class="content">In ACM Transactions on Graphics (<strong>SIGGRAPH</strong>), 2017</p>
				<p class="content">
				<strong> <a href="http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/SIG17/lfv/">Project</a></strong> |
				<strong> <a href="https://github.com/junyanz/light-field-video">GitHub</a></strong> |
			  <strong> <a href="https://youtu.be/TqVKcssYfAo">Youtube</a></strong> |
				<strong> <a href="http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/SIG17/lfv/paperData/LF_video_Code_v1.1.zip">Training code</a></strong> <br>
				<strong> <a href="https://arxiv.org/abs/1705.02997">Paper</a></strong> |
			  <strong> <a href="http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/SIG17/lfv/paperData/LF_video.mp4">Video</a><a></a></strong><a> |
				<strong> </strong></a><strong><a href="http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/SIG17/lfv/paperData/LF_video_Dataset.zip">Data (18GB)</a><a></a></strong><a> |
		    <strong> </strong></a><strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/lfv/lfv.txt">BibTex</a> </strong></p>
      </td></tr>
</tbody></table>

<p class="margin">&nbsp;</p>
<table border="0">
  <tbody><tr>
    <td width="140"><a href="https://people.eecs.berkeley.edu/~junyanz/projects/gvm/index.html"><img src="./Jun-Yan Zhu&#39;s Homepage_files/eccv16_gvm.gif" border="1" width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><strong>Generative Visual Manipulation on the Natural Image Manifold</strong></p>
      <p class="content">Jun-Yan Zhu, <a href="http://www.philkr.net/">Philipp Kr&#228;henb¨¹hl</a>, <a href="http://www.adobe.com/technology/people/seattle/eli-shechtman.html">Eli Shechtman</a>, and <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a></p>
      <p class="content">In European Conference on Computer Vision (<strong>ECCV</strong>), 2016</p>
	   <p class="content">See <strong> <a href="http://alumni.berkeley.edu/california-magazine/winter-2016-reality-bites/paint-numbers-algorithms-artistically-challenged">article</a> </strong> in California Magazine
      </p><p class="margin-small">&nbsp;</p>
	   <p class="content">
      <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/gvm/index.html">Project</a> </strong> |
			<strong><a href="https://youtu.be/9c4z6YsBGQ0">YouTube</a> </strong> |
			<strong><a href="https://github.com/junyanz/iGAN">GitHub</a>  </strong> |
			<strong><a href="https://arxiv.org/pdf/1609.03552v2.pdf">Paper</a></strong><br>
      <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/gvm/gvm_slides.pptx"> Slides </a> </strong> |
			<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/gvm/gvm_video.mp4"> Video </a> </strong> |
			 <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/gvm/eccv16_gvm.bib"> BibTex </a></strong></p>
      </td></tr>
</tbody></table>

<p class="margin">&nbsp;</p>
<table border="0">
  <tbody><tr>
    <td width="140"><a href="https://people.eecs.berkeley.edu/~junyanz/projects/lfmr/eccv16_lfmr.pdf"><img src="./Jun-Yan Zhu&#39;s Homepage_files/eccv16_lfmr.jpg" border="1" width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><strong>A 4D Light-Field Dataset and CNN Architectures for Material Recognition</strong></p>
      <p class="content"><a href="https://people.eecs.berkeley.edu/~tcwang0509/">Ting-Chun Wang</a>, Jun-Yan Zhu, Ebi Hiroaki, <a href="http://www.nec-labs.com/~manu/">Manmohan Chandraker</a>, <a href="http://www.eecs.berkeley.edu/~efros/"> Alexei A. Efros</a>, and <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a></p>
      <p class="content">In European Conference on Computer Vision (<strong>ECCV</strong>), 2016</p>
      <p class="margin-small">&nbsp;</p>
     <p class="content">
      <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/lfmr/eccv16_lfmr.pdf">Paper</a></strong> |
			<strong><a href="https://people.eecs.berkeley.edu/~tcwang0509/papers/ECCV16/dataset.html">Data (thumbnail)</a></strong> |
			<strong><a href="http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV16/LF_dataset.zip">Full data (15.9G)</a></strong> <br>
      <strong><a href="https://people.eecs.berkeley.edu/~tcwang0509/papers/ECCV16/full_scene.html">Supplement</a></strong> |
			<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/lfmr/lfmr_poster.pdf">Poster</a> </strong> |
			<strong> <a href="https://people.eecs.berkeley.edu/~junyanz/projects/lfmr/eccv16_lfmr.bib">BibTex</a></strong> </p>
      </td></tr>
</tbody></table>



<p class="margin">&nbsp;</p>
<table border="0">
  <tbody><tr>
    <td width="140"><a href="https://people.eecs.berkeley.edu/~junyanz/projects/realism/index.html"><img src="./Jun-Yan Zhu&#39;s Homepage_files/iccv15_realism.jpg" border="1" width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><strong>Learning a Discriminative Model for the Perception of Realism in Composite Images</strong></p>
      <p class="content">Jun-Yan Zhu, <a href="http://www.philkr.net/">Philipp Kr&#228;henb¨¹hl</a>, <a href="http://www.adobe.com/technology/people/seattle/eli-shechtman.html">Eli Shechtman</a>, and <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a></p>
      <p class="content">In IEEE International Conference on Computer Vision (<strong>ICCV</strong>), 2015</p>
      <p class="margin-small">&nbsp;</p>
	   <p class="content">
      <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/realism/index.html">Project</a></strong> |
			<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/realism/iccv15_realism.pdf">Paper</a> </strong> |
			<strong><a href="https://github.com/junyanz/RealismCNN">GitHub</a></strong> |
	   <strong> <a href="https://people.eecs.berkeley.edu/~junyanz/projects/realism/realism_slides.pptx"> Slides </a> </strong> |
			 <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/realism/realism_poster.pdf"> Poster </a></strong> |
				 <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/realism/iccv15_realism.bib"> BibTex </a> </strong></p><strong>
      </strong></td></tr>
</tbody></table>

<p class="margin">&nbsp;</p>
<table border="0">
  <tbody><tr>
    <td width="140"><a href="https://people.eecs.berkeley.edu/~junyanz/projects/mirrormirror/index.html"><img src="./Jun-Yan Zhu&#39;s Homepage_files/mirrormirror.jpg" border="1" width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><strong>Mirror Mirror: Crowdsourcing Better Portraits</strong></p>
      <p class="content">Jun-Yan Zhu, <a href="http://www.agarwala.org/index.html">Aseem Agarwala</a>, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, <a href="http://www.adobe.com/technology/people/seattle/eli-shechtman.html">Eli Shechtman</a>, and <a href="http://www.juew.org/"> Jue Wang</a></p>
      <p class="content">In ACM Transactions on Graphics (<strong>SIGGRAPH Asia</strong>), 2014</p>
      <p class="margin-small">&nbsp;</p>
	   <p class="content">
      <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/mirrormirror/index.html">Project (code)</a></strong> |
			<strong> <a href="https://people.eecs.berkeley.edu/~junyanz/projects/mirrormirror/mirrormirror_small.pdf">Paper</a></strong> |
			<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/mirrormirror/data.zip">Data</a></strong> |
	    <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/mirrormirror/mirrormirror_slides.pptx">Slides</a></strong> |
	     <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/mirrormirror/mirrormirror_supp.pdf">Supplement</a></strong> |
	     <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/mirrormirror/mirrormirror.bib">BibTex</a></strong></p>
      </td></tr>
</tbody></table>

<table border="0">
  <tbody><tr>
    <td width="140"><a href="https://people.eecs.berkeley.edu/~junyanz/projects/averageExplorer/index.html"><img src="./Jun-Yan Zhu&#39;s Homepage_files/sig14_cat_small.gif" border="1" width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><strong>AverageExplorer: Interactive Exploration and Alignment of Visual Data Collections</strong></p>
      <p class="content">Jun-Yan Zhu, <a href="http://www.cs.ucdavis.edu/~yjlee/">Yong Jae Lee</a> and <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a></p>
      <p class="content">In ACM Transactions on Graphics (<strong>SIGGRAPH</strong>), 2014</p>
      <p class="margin-small">&nbsp;</p>
       <p class="content">See <strong> <a href="http://www.newyorker.com/tech/elements/out-of-many-one">article</a> </strong> in The New Yorker
      </p><p class="content"><strong> <a href="https://people.eecs.berkeley.edu/~junyanz/projects/averageExplorer/index.html">Project</a> </strong>
      <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/averageExplorer/averageExplorer.pdf"></a></strong> |
      <strong><a href="http://youtu.be/1QgL_aPPCpM">YouTube</a></strong> |
			<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/averageExplorer/averageExplorer.pdf"> Paper</a></strong> |
        <strong> <a href="https://people.eecs.berkeley.edu/~junyanz/projects/averageExplorer/averageExplorer_slides.pptx">Slides</a></strong> |
        <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/averageExplorer/averageExplorer_supp.pdf">Supplement</a></strong> |
        <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/averageExplorer/average_explorer.bib">BibTex</a></strong></p>
      </td></tr>
</tbody></table>


<p class="margin-small">&nbsp;</p>
<table border="0">
  <tbody><tr>
    <td width="210"><img src="./Jun-Yan Zhu&#39;s Homepage_files/milcut.jpg" border="1" height="140" width="210"></td>
    <td width="20"></td>
    <td width="800"><p class="content"><strong>MILCut: A Sweeping Line  Multiple Instance Learning Paradigm for Interactive Image  Segmentation</strong></p>
      <p class="content"><a href="http://jiajunwu.com/">Jiajun Wu</a>*, <a href="http://www.stat.ucla.edu/~yibiao.zhao/">Yibiao Zhao</a>*, Jun-Yan Zhu, Siwei Luo and <a href="http://pages.ucsd.edu/~ztu/">Zhuowen Tu</a></p>
      <p class="content">In IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2014</p>
			<p class="content">(*indicates equal contributions)</p>
      <p class="margin-small">&nbsp;</p>
      <p class="content">
				 <strong><a href="http://jiajunwu.com/projects/milcut.html">Project </a></strong> |
				 <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/MILCut/cvpr14_milcut.pdf">Paper </a></strong> |
				 <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/MILCut/cvpr14_milcut_poster.pdf">Poster</a></strong> |
				 <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/MILCut/cvpr14_milcut.bib">BibTex</a></strong></p></td>
  </tr>
</tbody></table>

<p class="margin-small">&nbsp;</p>
<table border="0">
    <tbody> <tr>
      <td><img src="./Jun-Yan Zhu&#39;s Homepage_files/reverse_seg.jpg" border="1" height="140" width="210"></td>
      <td width="20"></td>
      <td width="800"><p class="content"><strong>Reverse Image Segmentation: A High-Level Solution to a Low-Level Task</strong></p>
        <p class="content"><a href="http://jiajunwu.com/">Jiajun Wu</a>, Jun-Yan Zhu, and <a href="http://pages.ucsd.edu/~ztu/">Zhuowen Tu</a></p>
        <p class="content">In British Machine Vision Conference (<strong>BMVC</strong>), 2014</p>
        <p class="margin-small">&nbsp;</p>
      <p class="content">
				<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/reverse_seg/reverse_seg.pdf">Paper</a></strong> |
				<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/reverse_seg/reverse_seg.bib">BibTex</a></strong></p></td>
    </tr>
  </tbody>
</table>


<p class="margin-small">&nbsp;</p>
<table border="0">
  <tbody><tr>
    <td width="140"><a href="https://people.eecs.berkeley.edu/~junyanz/projects/bMCL/"><img src="./Jun-Yan Zhu&#39;s Homepage_files/bmcl.jpg" border="1" height="140" width="210"></a></td>
    <td width="20"></td>
    <td width="800"><p class="content"><strong>Unsupervised Object Class Discovery via Saliency-Guided Multiple Class Learning</strong></p>
      <p class="content">Jun-Yan Zhu, <a href="http://jiajunwu.com/">Jiajun Wu</a>, <a href="http://bme.buaa.edu.cn/teacherInfo.aspx?catID=7&amp;subcatID=141&amp;curID=355">Yan Xu</a>, <a href="http://research.microsoft.com/en-us/people/echang/">Eric Chang</a> and <a href="http://pages.ucsd.edu/~ztu/">Zhuowen Tu</a></p>
      <p class="content">In  IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2015</p>
      <p class="content">(an expanded journal version of our <strong>CVPR</strong> 2012 <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/bMCL/cvpr12_bmcl.pdf">paper</a></strong>)</p>
      <p class="margin-small">&nbsp;</p>
      <p class="content"><strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/bMCL/index.html">Project</a></strong> |
			<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/bMCL/pami_bmcl.pdf">Paper</a></strong> |
      <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/bMCL/bMCL_supp.pdf">Supplement</a></strong> |
			<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/bMCL/cvpr12_bmcl_poster.pdf">Poster</a></strong> |
			<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/bMCL/pami_bmcl.bib">BibTex</a></strong></p></td>
  </tr>
</tbody></table>

<p class="margin-small">&nbsp;</p>
<table border="0">
  <tbody><tr>
    <td width="140"><a href="https://people.eecs.berkeley.edu/~junyanz/projects/MCIL/"><img src="./Jun-Yan Zhu&#39;s Homepage_files/mia14_mcil.jpg" border="1" height="140" width="210"></a></td>
    <td width="20"></td>
    <td width="800"><p class="content"><strong>Multiple Clustered Instance Learning for Histopathology Cancer Image Classification, Segmentation and Clustering</strong></p>
      <p class="content"><a href="http://bme.buaa.edu.cn/teacherInfo.aspx?catID=7&amp;subcatID=141&amp;curID=355">Yan Xu</a>*, Jun-Yan Zhu*, <a href="http://research.microsoft.com/en-us/people/echang/">Eric I-Chao Chang</a> and <a href="http://pages.ucsd.edu/~ztu/">Zhuowen Tu</a></p>
      <p class="content">In IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2012</p>
			<p class="content">(*indicates equal contributions)</p>
      <p class="content">(See an expanded journal <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/MCIL/mia14_mcil.pdf"> version</a></strong> at Medical Image Analysis (<strong>MIA</strong>), 2014</p>
      <p class="margin-small">&nbsp;</p>
      <p class="content"><strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/MCIL/index.html">Project</a></strong> |
      <strong><a href="https://github.com/junyanz/MCILBoost">GitHub</a></strong> |
			<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/MCIL/cvpr12_mcil.pdf">Paper</a></strong> |
			<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/MCIL/cvpr12_mcil.bib">BibTex</a></strong> |
			<strong> <a href="https://people.eecs.berkeley.edu/~junyanz/projects/MCIL/cvpr12_mcil_poster.pdf">Poster</a></strong></p></td>
  </tr>
</tbody></table>


<p class="margin-small">&nbsp;</p>
<table border="0">
  <tbody><tr>
    <td width="140"><img src="./Jun-Yan Zhu&#39;s Homepage_files/tip13_videoblend.gif" border="1" height="140" width="210"></td>
    <td width="20"></td>
    <td width="800"><p class="content"><strong>Motion-Aware Gradient Domain Video Composition</strong></p>
      <p class="content"><a href="http://www.ee.columbia.edu/ln/dvmm/vso/~taochen/">Tao Chen</a>, Jun-Yan Zhu, <a href="http://www.faculty.idc.ac.il/arik/site/index.asp">Ariel Shamir</a> and <a href="http://cg.cs.tsinghua.edu.cn/prof_hu.htm">Shi-Min Hu</a></p>
      <p class="content">In IEEE Transactions on Image Processing (<strong>TIP</strong>), 2013</p>
      <p class="margin-small">&nbsp;</p>
      <p class="content">
				<strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/videoblend/videoblend.pdf">Paper</a></strong> |
	  <strong><a href="http://youtu.be/AK2m4holVns">YouTube</a></strong> |
	  <strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/videoblend/videoblend.mp4">Video</a></strong> |
	  <strong> <a href="https://people.eecs.berkeley.edu/~junyanz/projects/videoblend//videoblend.bib">BibTex</a></strong></p></td>
  </tr>
</tbody></table>



<br>


<p class="title-large">Software</p>

<p class="content"><strong><a href="https://github.com/junyanz/interactive-deep-colorization">Interactive Deep Colorization</a></strong>: a user interface for real-time user-guided colorization.</p>
<p class="content"><strong><a href="https://github.com/junyanz/light-field-video">Light Field Video</a></strong>: Light field video applications (e.g. video refocusing, changing aperture and view).</p>
<p class="content"><strong><a href="https://github.com/junyanz/CycleGAN">CycleGAN</a></strong>: Torch implementation for learning an image-to-image translation without input-output pairs.</p>
<p class="content"><strong><a href="https://github.com/phillipi/pix2pix">pix2pix</a></strong>: Torch implementation for learning a mapping from input images to output images.</p>
<p class="content"><strong><a href="https://github.com/junyanz/CycleGAN">pytorch CycleGAN &amp; pix2pix</a></strong>: PyTorch implementation for both unpaired and paired image-to-image translation.</p>
<p class="content"><strong><a href="https://github.com/junyanz/iGAN">iGAN</a></strong>: a deep learning software that easily generates images with a few brushstrokes.</p>
<p class="content"><strong><a href="https://github.com/junyanz/RealismCNN">RealismCNN</a></strong>: code for predicting and improving visual realism in composite images.</p>
<p class="content"><strong><a href="https://github.com/junyanz/MCILBoost">MCILBoost</a></strong>: a boosting-based Multiple Instance Learning (MIL) software.</p>
<p class="content"><strong><a href="https://github.com/junyanz/MirrorMirror">MirrorMirror</a></strong>: an expression training App that helps users mimic their own expressions.</p>
<p class="content"><strong><a href="https://github.com/junyanz/SelectGoodFace">SelectGoodFace</a></strong>: a program for selecting attractive/serious portraits from a personal photo collection.</p>
<p class="content"><strong><a href="https://github.com/junyanz/FaceDemo">FaceDemo</a></strong>: a simple 3D face alignment and warping demo.</p>

<br>

<p class="title-large">Talks</p>
<p class="content"><strong><a href="https://people.eecs.berkeley.edu/~junyanz/talks/talk_natural_photos.pptx">Learning to Synthesize and Manipulate Natural Photos</a></strong></p>
<p class="content">MIT CSAIL, HKUST CSE Departmental seminar, O'Reilly AI, AI with the best, Y Conf, etc. (2017)</p>

<p class="content"><strong><a href="https://people.eecs.berkeley.edu/~junyanz/talks/ideepcolor.pptx">Interactive Deep Colorization</a></strong></p>
<p class="content">SIGGRAPH, NVIDIA Innovation Theater, Global AI Hackathon (2017)</p>

<p class="content"><strong><a href="https://people.eecs.berkeley.edu/~junyanz/talks/manipulation_synthesis_junyanz.pptx">Visual Manipulation and Synthesis on the Natural Image Manifold</a></strong></p>
<p class="content"> Facebook, MSR, Berkeley BAIR, Tsinghua, Fudan Univ, ICML workshop "Visualization for Deep Learning" (2016)</p>

<p class="content"><strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/mirrormirror/mirrormirror_slides.pptx">Mirror Mirror: Crowdsourcing Better Portraits</a></strong></p>
<p class="content">SIGGRAPH Asia (2014)</p>
<p class="content"><strong><a href="https://people.eecs.berkeley.edu/~junyanz/talks/siga14_course_ddvc_junyanz.pdf">What Makes Big Visual Data Hard?</a></strong></p>
<p class="content">SIGGRAPH Asia invited course "Data-Driven Visual Computing" (2014)</p>
<p class="content"><strong><a href="https://people.eecs.berkeley.edu/~junyanz/projects/averageExplorer/averageExplorer_slides.pptx">AverageExplorer: Interactive Exploration and Alignment of Visual Data Collections</a></strong></p>
<p class="content">SIGGRAPH (2014)</p>
<p class="content"><strong><a href="https://people.eecs.berkeley.edu/~junyanz/talks/wsl_slides.pptx">Discovering Objects and Harvesting Visual Concepts via Weakly Supervised Learning</a></strong></p>
<p class="content"> Berkeley Visual Computing Lab (2014)</p>
<br>


<p class="title-large">Awards</p>
<p class="content">Facebook Fellowship (2015-2017)</p>
<p class="content">Outstanding Undergraduate Thesis in Tsinghua University (2012)</p>
<p class="content">Excellent Undergraduate Student in Tsinghua University (2012)</p>
<p class="content">National Scholarship,  by Ministry of Education of China (2009 and 2010)</p>
<p class="content"> Singapore Technologies Engineering China Scholarship (2010, 2011, and 2012)</p>
<br>

<p class="title-large">MISC</p>
<p class="content">Here is my cat <strong><a href="https://people.eecs.berkeley.edu/~junyanz/imgs/cat_portrait.jpg">Aquarius</a></strong>.</p>

<div style="display:none">
<!-- GoStats JavaScript Based Code -->
<script type="text/javascript" src="./Jun-Yan Zhu&#39;s Homepage_files/counter.js.download"></script>
<script type="text/javascript">_gos='c3.gostats.com';_goa=390583;
_got=4;_goi=1;_goz=0;_god='hits';_gol='web page statistics from GoStats';_GoStatsRun();</script>
<!-- <a target="_blank" title="web page statistics from GoStats"
href="http://gostats.com"> -->
</div>
<!--
<img alt="web page statistics from GoStats"
src="http://c3.gostats.com/bin/count/a_390583/t_4/i_1/z_0/show_hits/counter.png"
style="border-width:0" />
</a>
-->
<!-- End GoStats JavaScript Based Code -->

</body></html>